---
title: "XGBoost Model"
author: "Audrey Garcia"
date: "`r Sys.Date()`"
output: pdf_document
always_allow_html: true
---

```{r}
library(tidyverse)
library(mlr3verse)
```

```{r}
# Save Rmd in a folder that also includes the ucla-stats-101-c-fall-2025-regression folder 
amazon_purchases <- read_csv("amazon-purchases.csv")
fields <- read_csv("fields.csv")
survey_train_test <- read_csv("survey_train_test.csv")
```

```{r}
# Problem description says:
# "removed all information from the test data that wouldn't be known at sign-up (you only have ResponseID, Gender, and state)"
# but he didn't...
# so I did here


survey <- survey_train_test |>
  select(Survey.ResponseID, Q.demos.gender, Q.demos.state, Q.amazon.use.hh.size.num, test) |>
  mutate(Q.demos.gender = as.factor(Q.demos.gender)) |> 
  mutate(Q.demos.state = as.factor(Q.demos.state)) |>
  rename(Gender = Q.demos.gender, State = Q.demos.state)
```

```{r}
amazon <- amazon_purchases |>
  rename(Survey.ResponseID = `Survey ResponseID`)
fulldata <- left_join(amazon, survey, by = "Survey.ResponseID")
```

```{r}
fulldata <- fulldata |> 
  mutate(Day = day(`Order Date`), Month = month(`Order Date`), Year = year(`Order Date`)) |>
  select(-`Order Date`, -Title, -`ASIN/ISBN (Product Code)`, -`Shipping Address State`)

pivoted <- fulldata |>
  group_by(Survey.ResponseID, Category) |>
  summarize(Count = sum(Quantity)) |> 
  pivot_wider(names_from = Category, values_from = Count, values_fill = 0)

joined <- pivoted |>
  left_join(survey, by = "Survey.ResponseID")

training <- joined |>
  filter(test == FALSE)
testing <- joined |>
  filter(test == TRUE)
```

# Model 1: Rpart Decision Tree
```{r}
library(rpart)
library(rpart.plot)
rpart_task <- as_task_regr(training, target = "Q.amazon.use.hh.size.num")
set.seed(12)

tree_learner <- as_learner(
  ppl("robustify") %>>%
  lrn("regr.rpart")
)

tree_learner$train(rpart_task)

tree_learner$model$regr.rpart$model

tree_learner$model$regr.rpart$model |> rpart.plot()

vip::vip(tree_learner$model$regr.rpart$model)

tree_learner$model$regr.rpart$param_vals


```





# Model 2: random forest
```{r}
library(vip)
rf_task <- as_task_regr(training, target = "Q.amazon.use.hh.size.num")

rf_learner <- as_learner(
  ppl("robustify") %>>%
  lrn("regr.ranger", importance = "impurity")
)

rf_learner$train(rf_task)

rf_learner$model$regr.ranger$model$model

vip::vip(rf_learner$model$regr.ranger$model$model)

rf_learner$model$regr.ranger$param_vals

```








# Final Model : XGBoost
```{r}
xg_task <- as_task_regr(joined, target = "Q.amazon.use.hh.size.num")
set.seed(12) # for group 12 :)

lrn_xgboost <- as_learner(
  ppl("robustify") %>>%
  lrn("regr.xgboost",
    eta = to_tune(1e-4, 1, logscale = TRUE),
    max_depth = to_tune(1, 10),
    colsample_bytree = to_tune(1e-1, 1),
    colsample_bylevel = to_tune(1e-1, 1),
    lambda = to_tune(1e-3, 1e3, logscale = TRUE),
    alpha = to_tune(1e-3, 1e3, logscale = TRUE),
    subsample = to_tune(1e-1, 1)
))

at_xgb = auto_tuner( 
  tuner = tnr("random_search"),
  term_evals = 700, 
  learner = lrn_xgboost, 
  resampling = rsmp("holdout"), ### "holdout"
  measure = msr("regr.rmse")
)

```

```{r}
# Hyperparameter tuning
# commented out for quicker run time
# HOWEVER, to achieve exact results as submitted, proceed using the complete hypertuning process
# (roundoff errors)

# at_xgb$train(xg_task , row_ids = which(joined$test == FALSE))
# best_xgb <- at_xgb$learner$clone(deep = TRUE)
```

```{r}
# best_xgb <- at_xgb$learner$clone(deep = TRUE)

# tuned_hyperparams <- best_xgb$model$regr.xgboost$param_vals


best_xgb <- as_learner(
  ppl("robustify") %>>%
  lrn("regr.xgboost")
)
best_xgb$pipeops_param_set_values$regr.xgboost = list(
      alpha = 0.0585235,
      colsample_bylevel = 0.3437478,
      colsample_bytree = 0.9904165,
      eta = (0.003094458),
      lambda = (0.0179533),
      max_depth = 8,
      nrounds = 1000,
      nthread = 1,
      subsample = 0.40495
)


```


```{r}
# Cross-Validation and Error Metrics : Benchmarking
training <- joined |>
  filter(test == FALSE)
testing <- joined |>
  filter(test == TRUE)

task_cv <- as_task_regr(training, target = "Q.amazon.use.hh.size.num")

resampler <- rsmp("cv", folds = 5)

learners <- lrns(c("regr.rpart", "regr.ranger")) # finish this
learners$regr.rpart = tree_learner
learners$regr.ranger = rf_learner
learners$regr.xgboost = best_xgb

bmr_design <- benchmark_grid(tasks = task_cv,
                             learners = learners,
                             resamplings = resampler)

bmr <- benchmark(design = bmr_design)

bmr$aggregate(measures = msr("regr.rmse"))

autoplot(bmr)

```



# Training and Predicting Final Model for Submission
```{r}
best_xgb$train(xg_task , row_ids = which(joined$test == FALSE))
```

```{r}
prediction <- best_xgb$predict(xg_task, row_ids = which(joined$test == TRUE))
```

```{r}
submission <- cbind(joined$Survey.ResponseID[which(joined$test == TRUE)], prediction$response) |>
  as.data.frame()
names(submission) <- c("Survey.ResponseID", "Q.amazon.use.hh.size.num")
```

```{r}
write_csv(submission, "submission.csv")
```


```{r}
# Plot one tree of xgb model
# commented out for pdf knitting

library(xgboost)
# xgboost::xgb.plot.tree(model = best_xgb$model$regr.xgboost$model, trees = 1)
```



